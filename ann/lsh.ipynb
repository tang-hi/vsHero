{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH(Locality Sensitive Hashing)\n",
    "LSH算法是一个被广泛使用的ANN算法，它可以在保证质量较高的搜索结果的同时，仍然保持高效的搜索速度。我们在这一章会阐述LSH的原理，同时用python实现一个自己的LSH搜索引擎。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to LSH!\n"
     ]
    }
   ],
   "source": [
    "print('Welcome to LSH!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "如果你已经下载了数据，可以直接跳过这个cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import urllib.request as request\n",
    "import tarfile\n",
    "from contextlib import closing\n",
    "\n",
    "# download the Sift1M dataset\n",
    "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/siftsmall.tar.gz')) as r:\n",
    "    with open('sift.tar.gz', 'wb') as f:\n",
    "        shutil.copyfileobj(r, f)\n",
    "\n",
    "\n",
    "# the download leaves us with a tar.gz file, we unzip it\n",
    "tar = tarfile.open('sift.tar.gz', \"r:gz\")\n",
    "tar.extractall()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在讲LSH算法之前，我们先回忆一下我们平时接触到的HASH算法。他们有以下几个特点\n",
    "1. 如果两个元素完全相同(每个bit都一样),那么会产生相同的hashcode。\n",
    "2. 如果两个元素哪怕只有一个bit不同，最后产生的hashcode也会相差较大。\n",
    "\n",
    "但是这样的HASH算法并不适合我们的ANN搜索。举一个例子，比如说我们有下面两篇文档\n",
    "> I like dog\n",
    "\n",
    "> I really like dog\n",
    "\n",
    "如果我们使用传统的hash算法，即使这两篇文档只差了一个**really**，仍旧会产生完全不同的hashcode\n",
    "| doc | MD5 | SHA1 |\n",
    "| --- | --- | ---- |\n",
    "|I like dog| 8a8249c0591b1c9aacc86f7a7e62fec3 | cf8ddb14b51c85d344cc7d841be5963b60a6d1a6 |\n",
    "|I really like dog| 28316b7215c792aeea598f132e9e9541 | f541e674f949f39a5c1df53e45b46f0b5d518820 |\n",
    "\n",
    "这就意味着如果我们基于hash来进行搜索,当输入为`I like dog`时,我们无法检索到`I really like dog`,这显然不是我们所期望的。而LSH通过巧妙的方法，让我们可以通过基于hash的方式，来搜索到相似的文档。\n",
    "\n",
    "LSH的主要思想可以归纳为\n",
    "1. 如果两篇文档相似，那么让他们的hashcode尽可能的相同，即发生碰撞。\n",
    "2. 如果两篇文档不相似，那么尽可能的让他们hashcode不相同。\n",
    "\n",
    "为此，我们需要有一个hash函数可以满足上述的两个要求。常见的hash函数有**MinHash**、**Random Projection**和**Cosine Similarity Hashing**等。本章的后续篇幅主要介绍**Random Projection**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Projection\n",
    "为了便于理解，我们从一个三维的例子出发.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src=\"./resources/lsh_1.png\"/>\n",
    "</div>\n",
    "\n",
    "假设我们现在向量空间中有六个点，我们可以任意选择一个超平面，这个超平面会将整个向量空间一分为2.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src=\"./resources/lsh_2.png\"/>\n",
    "</div>\n",
    "\n",
    "从图中我们可以看到，点A，B，C，D处于超平面的正面，而点E，F则处于超平面的负面。因此我们可以将A，B，C，D的hashcode设置为1, 点E，F的hashcode设置为0。这种hash方式符合LSH的要求，即相似的向量hashcode相同。\n",
    "\n",
    "````\n",
    "Hash(A) = Hash(B)\n",
    "Hash(C) = Hash(D)\n",
    "Hash(E) = Hash(F)\n",
    "````\n",
    "但是LSH的第二个要求并不满足，我们的`Hash(A) == Hash(C)`, 根据要求,我们应该有`Hash(A) != Hash(C)`。为了解决这个问题，我们可以再多加一个超平面.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src=\"./resources/lsh_3.png\"/>\n",
    "</div>\n",
    "\n",
    "通过增加超平面的方式，我们可以将hashcode从一个比特变成两个比特,也完成了LSH的hash函数要求。\n",
    "````\n",
    "Hash(A) = Hash(B) = 10\n",
    "Hash(C) = Hash(D) = 11\n",
    "Hash(A) = Hash(B) = 01\n",
    "\n",
    "````\n",
    "上述的方法就是随机投影法。我们通过随机生成固定数量N的超平面后，根据向量是处在超平面的正面还是负面，将向量hash为Nbit的hashcode。这一方法符合直觉，如果两个点相似，即距离相近，那么通过随机投影，他们会有较高的概率拥有相同的hashcode，但如果相距较远，他们的拥有相同的hashcode概率也会较低。同时计算一个点在超平面的正面还是负面也相当简单，你只需要对他们做点积即可。\n",
    "````python\n",
    "if np.dot(a, hyper_plane.T) > 0:\n",
    "    return 1\n",
    "return 0 \n",
    "\n",
    "````\n",
    "因此我们可以低成本的计算出向量的hashcode。\n",
    "\n",
    "然而随机投影仍然有一个问题，需要我们去解决，即考虑下图的情况,我们随机生成的超平面将C，D两点隔开，也就是说C，D的hashcode将会不同，这与我们之前的假设相违背，即相似的向量应该具有相同的hashcode\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src=\"./resources/lsh_final.png\"/>\n",
    "</div>\n",
    "\n",
    "为了解决上述问题，我们在计算完所有点的hashcode后，将hashcode相同的点放入同一个bucket中。再次随机生成超平面，重新计算所有点的hashcode，再将hashcode相同的点放到新的bucket中。\n",
    "如下图所示,我们通过不同的hash函数(随机投影)对向量计算hashcode。\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src=\"./resources/hash_process.png\"/>\n",
    "</div>\n",
    "\n",
    "在搜索时，我们会使用对应的的hash函数(随机投影)得到查询向量的hashcode，并去对应的bucket中计算距离，最终得出结果，举个例子\n",
    "假设我们有查询向量Q, K = 2\n",
    "````\n",
    "Hash1(Q) = 000\n",
    "Hash2(Q) = 001\n",
    "\n",
    "````\n",
    "我们分别会去和Bucket1以及Bucket5中的向量计算向量距离，然后返回距离最近的两个。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab\n",
    "\n",
    "在这个Lab中你需要实现 `add_vec` 以及 `topK` 函数。\n",
    "#### HINT\n",
    "1. LSH的初始化代码已经为你准备好了\n",
    "    - nbits 表示hashcode有几位\n",
    "    - n_buckets 表示LSH需要几个hash函数来计算不同的hashcode\n",
    "    - d 表示数据的维数 \n",
    "    - self.hashes 存放的是随机生成的投影即hash函数, 长度为n_buckets, `self.hashes[i]` 代表第i个hash函数\n",
    "    - self.buckets 存放的是向量数据，`self.buckets[i][key]` 代表使用第i个hash函数且hashcode为value的所有向量\n",
    "2. `distance` 函数也已经帮你实现了，我们仍旧使用欧式距离来衡量向量之间的距离。\n",
    "3. `cal_hashcode` 函数会帮你计算向量的hashcode，需要你输入向量，以及使用第几个hash函数，输出为hashcode。\n",
    "4. `add_vec` 需要你进行实现，你首先需要计算向量的hashcode，然后根据使用的hash函数，以及hashcode，将向量存入相应的bucket中，注意，你不需要存储原始向量，你只需要存入参数`label`即可\n",
    "5. `topK` 你需要根据查询的向量，以及LSH的查找流程，找到距离最近的`K`个向量后返回，注意，你无需返回原始向量，你只要返回向量对应的label即可\n",
    "\n",
    "当你全部实现后，你可以运行后续的cell，我们会用不同的 **nbits**，以及 **n_buckets** 计算对应的krecall以及查询时间，并绘制图片。\n",
    "> krecall 表示topK返回的结果中有多少比例的向量属于KNN的topK返回的结果。\n",
    "\n",
    "> 图中的的点会以b${x}n${y}命名，其中x表示nbits的大小，${y}表示n_buckets的大小。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Utils for read database\n",
    "\"\"\"\n",
    "def read_fvecs(file: str) -> np.ndarray:\n",
    "    fv = np.fromfile(file, dtype=np.float32)\n",
    "    if fv.size == 0:\n",
    "        return np.zeros((0, 0))\n",
    "    dim = fv.view(np.int32)[0]\n",
    "    return fv.reshape(-1, dim + 1)[:, 1:].copy().view('float32')\n",
    "\n",
    "\n",
    "def read_ivecs(file: str) -> np.ndarray:\n",
    "    ground_truth = np.fromfile(file, dtype=np.int32)\n",
    "    if ground_truth.size == 0:\n",
    "        return ground_truth.zeros((0, 0))\n",
    "    d = ground_truth[0]\n",
    "    return ground_truth.reshape(-1, d+1)[:, 1:].copy().view('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import heapq\n",
    "def all_keys(n):\n",
    "    \"\"\"\n",
    "    Generates all binary keys with a given number of bits.\n",
    "\n",
    "        Args:\n",
    "            n (int): The number of bits for each binary key.\n",
    "\n",
    "        Returns:\n",
    "            list[str]: A list of binary keys with the specified number of bits.\n",
    "    generate all keys for nbits\n",
    "    example:\n",
    "        n = 2\n",
    "        all_keys(n) result is ['00', '01', '10', '11']\n",
    "    \"\"\"\n",
    "\n",
    "    total = 1 << n\n",
    "    keys = []\n",
    "    for i in range(total):\n",
    "        binary = format(i, f'0{n}b')\n",
    "        keys.append(binary)\n",
    "    return keys\n",
    "\n",
    "# load dataset\n",
    "data_set = read_fvecs('./siftsmall/siftsmall_base.fvecs')\n",
    "# load all query \n",
    "query = read_fvecs('./siftsmall/siftsmall_query.fvecs')\n",
    "\n",
    "\n",
    "class LSH:\n",
    "    \"\"\"\n",
    "    LSH is a class that implements the Locality Sensitive Hashing (LSH) algorithm.\n",
    "\n",
    "    Attributes:\n",
    "        hashes (list[np.ndarray]): A list of NumPy arrays representing hash functions.\n",
    "        buckets (list[dict]): A list of dictionaries representing hash buckets.\n",
    "        nbits (int): The number of bits for each hash code.\n",
    "        n_buckets (int): The number of hash functions and buckets.\n",
    "        d (int): The dimension of the data points.\n",
    "        keys (list[str]): A list of binary keys with the specified number of bits.\n",
    "\n",
    "    Methods:\n",
    "        cal_hashcode(vec, bucket): Calculates the hash code for a given vector and hash function.\n",
    "        distance(v, u): Calculates the Euclidean distance between two points, v and u.\n",
    "        add_vec(vec, label): Adds a vector to the LSH hash table with a given label.\n",
    "        topK(vec, k): Finds the top k nearest neighbors for a given vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nbits, n_buckets, d) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the LSH class with the given parameters.\n",
    "\n",
    "        Args:\n",
    "            nbits (int): The number of bits for each hash code.\n",
    "            n_buckets (int): The number of hash functions and buckets.\n",
    "            d (int): The dimension of the data points.\n",
    "        \"\"\"\n",
    "\n",
    "        # hash function different bucket\n",
    "        self.hashes = []\n",
    "\n",
    "        # buckets map\n",
    "        self.buckets = []\n",
    "        self.nbits = nbits\n",
    "        self.n_buckets = n_buckets\n",
    "        self.d = d\n",
    "        self.keys = all_keys(nbits)\n",
    "        for i in range(n_buckets):\n",
    "            # store the hash function\n",
    "            self.hashes.append(np.random.rand(d, nbits) - .5)\n",
    "            self.buckets.append({})\n",
    "            for key in self.keys:\n",
    "                self.buckets[i][key] = []\n",
    "\n",
    "    def cal_hashcode(self, vec: np.ndarray, bucket: int) -> str:\n",
    "        \"\"\"\n",
    "        Calculates the hash code for a given vector and hash function.\n",
    "\n",
    "        Args:\n",
    "            vec (np.ndarray): A NumPy array representing the input vector.\n",
    "            bucket (int): The index of the hash function to use.\n",
    "\n",
    "        Returns:\n",
    "            str: The hash code of the input vector.\n",
    "        \"\"\"\n",
    "        result = np.dot(vec, self.hashes[bucket])\n",
    "        result = result > 0\n",
    "        hashcode = result.astype(int)\n",
    "        return ''.join(map(str, hashcode))\n",
    "\n",
    "    def distance(self, v: np.ndarray, u: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the Euclidean distance between two points, v and u.\n",
    "\n",
    "        Args:\n",
    "            v (np.ndarray): A NumPy array representing the first point.\n",
    "            u (np.ndarray): A NumPy array representing the second point.\n",
    "\n",
    "        Returns:\n",
    "            float: The Euclidean distance between points v and u.\n",
    "        \"\"\"\n",
    "        return np.linalg.norm(v - u)\n",
    "\n",
    "    def add_vec(self, vec: np.ndarray, label: int) -> None:\n",
    "        \"\"\"\n",
    "        Adds a vector to the LSH hash table with a given label.\n",
    "\n",
    "        Args:\n",
    "            vec (np.ndarray): A NumPy array representing the input vector.\n",
    "            label (int): The label associated with the input vector.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    def topK(self, vec: np.ndarray, k=10) -> list:\n",
    "        \"\"\"\n",
    "        Finds the top k nearest neighbors for a given vector using LSH.\n",
    "\n",
    "        Args:\n",
    "            vec (np.ndarray): A NumPy array representing the input vector.\n",
    "            k (int, optional): The number of nearest neighbors to find. Defaults to 10.\n",
    "\n",
    "        Returns:\n",
    "            list: A list containing the top k nearest neighbors.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ground_truth = np.fromfile(\n",
    "    \"./siftsmall/siftsmall_groundtruth.ivecs\", dtype=np.int32)\n",
    "d = ground_truth[0]\n",
    "gt = ground_truth.reshape(-1, d+1)[:, 1:].copy().view('int32')\n",
    "\n",
    "def intersection(lst1: list, lst2 : list) -> list:\n",
    "    return set(lst1).intersection(lst2)\n",
    "\n",
    "def k_recall(lsh, k = 10) -> tuple:\n",
    "    recall = 0.0\n",
    "    st = time.time()\n",
    "    times = 0\n",
    "    for query_idx in range(0, len(query)):\n",
    "        times += 1\n",
    "        result = lsh.topK(query[query_idx], k)\n",
    "        recall += (len(intersection(result, gt[query_idx][:k])) / k)\n",
    "    se = time.time()\n",
    "    return (recall / times, (se - st) / times)\n",
    "\n",
    "recalls = []\n",
    "times = []\n",
    "names = []\n",
    "# generate graph\n",
    "for nbits in range(2, 12, 2):\n",
    "    for n_bucket in range(1, 8, 3):\n",
    "        lsh = LSH(nbits, n_bucket, data_set.shape[1])\n",
    "        for label in range(0, len(data_set)):\n",
    "            lsh.add_vec(data_set[label], label)\n",
    "        recall, t = k_recall(lsh, 10)\n",
    "        recalls.append(recall)\n",
    "        times.append(t)\n",
    "        names.append(f'b{nbits}n{n_bucket}')\n",
    "        print(f'nbits {nbits}, bucket {n_bucket}, recall {recall}, time {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制折线图\n",
    "plt.scatter(times, recalls)\n",
    "for i, txt in enumerate(names):\n",
    "    plt.annotate(txt, (times[i], recalls[i]))\n",
    "plt.xlabel(\"execute time\")\n",
    "plt.ylabel(\"recall rate\")\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
